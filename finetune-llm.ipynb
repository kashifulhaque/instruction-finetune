{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7419775,"sourceType":"datasetVersion","datasetId":4316700}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Fine-tune LLM on custom dataset**\n\nArticle: [part 1](https://wandb.ai/capecape/alpaca_ft/reports/How-to-implement-fine-tuning-of-an-LLM-Part-1-Dataset-for-Instruction-Tuning--Vmlldzo1NTcxNzE2) [part 2](https://wandb.ai/capecape/alpaca_ft/reports/How-to-fine-tune-an-LLM-Part-2-Instruction-tuning-Llama-2--Vmlldzo1NjY0MjE1) \\\nCleaned dataset in use: [alpaca cleaned](https://github.com/gururise/AlpacaDataCleaned/blob/main/alpaca_data_cleaned.json)","metadata":{}},{"cell_type":"markdown","source":"## **Dependencies**","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:25:31.743571Z","iopub.execute_input":"2024-01-17T11:25:31.743982Z","iopub.status.idle":"2024-01-17T11:25:32.396430Z","shell.execute_reply.started":"2024-01-17T11:25:31.743950Z","shell.execute_reply":"2024-01-17T11:25:32.395064Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### **Load dataset**","metadata":{}},{"cell_type":"code","source":"import json\n\nfrom pprint import pprint","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:32:34.593538Z","iopub.execute_input":"2024-01-17T10:32:34.593949Z","iopub.status.idle":"2024-01-17T10:32:34.599262Z","shell.execute_reply.started":"2024-01-17T10:32:34.593918Z","shell.execute_reply":"2024-01-17T10:32:34.597790Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/input/alpaca-cleaned/alpaca_data_cleaned.json\", \"r\") as file:\n    alpaca = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:32:08.775924Z","iopub.execute_input":"2024-01-17T10:32:08.776266Z","iopub.status.idle":"2024-01-17T10:32:09.437340Z","shell.execute_reply.started":"2024-01-17T10:32:08.776242Z","shell.execute_reply":"2024-01-17T10:32:09.436315Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"len(alpaca)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:32:13.191520Z","iopub.execute_input":"2024-01-17T10:32:13.191897Z","iopub.status.idle":"2024-01-17T10:32:13.200085Z","shell.execute_reply.started":"2024-01-17T10:32:13.191868Z","shell.execute_reply":"2024-01-17T10:32:13.198748Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"51760"},"metadata":{}}]},{"cell_type":"code","source":"pprint(alpaca[123])","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:32:38.700096Z","iopub.execute_input":"2024-01-17T10:32:38.700448Z","iopub.status.idle":"2024-01-17T10:32:38.707163Z","shell.execute_reply.started":"2024-01-17T10:32:38.700392Z","shell.execute_reply":"2024-01-17T10:32:38.705891Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'input': '',\n 'instruction': \"Find the synonyms of the following word: 'Tenacious'.\",\n 'output': \"Here are some synonyms for the word 'Tenacious':\\n\"\n           '\\n'\n           '1. Persistent\\n'\n           '2. Determined \\n'\n           '3. Resolute \\n'\n           '4. Steadfast \\n'\n           '5. Obstinate\\n'\n           '6. Persevering\\n'\n           '7. Unyielding\\n'\n           '8. Unwavering\\n'\n           '9. Strong-willed\\n'\n           '10. Dogged.'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Preprocess the data**\nAs we have instructions both with and without prompts, hence each case must be dealt with them separately.","metadata":{}},{"cell_type":"code","source":"def prompt_no_input(row):\n    return (\"Below is an instruction that describes a task. \"\n            \"Write a response that appropriately completes the request.\\n\\n\"\n            \"### Instruction:\\n{instruction}\\n\\n### Response:\\n\").format_map(row)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:39:13.477220Z","iopub.execute_input":"2024-01-17T10:39:13.477605Z","iopub.status.idle":"2024-01-17T10:39:13.483088Z","shell.execute_reply.started":"2024-01-17T10:39:13.477572Z","shell.execute_reply":"2024-01-17T10:39:13.482056Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def prompt_input(row):\n    return (\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n            \"Write a response that appropriately completes the request.\\n\\n\"\n            \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\").format_map(row)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:39:13.628479Z","iopub.execute_input":"2024-01-17T10:39:13.629264Z","iopub.status.idle":"2024-01-17T10:39:13.633406Z","shell.execute_reply.started":"2024-01-17T10:39:13.629231Z","shell.execute_reply":"2024-01-17T10:39:13.631983Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(prompt_no_input(alpaca[123]))","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:39:19.768028Z","iopub.execute_input":"2024-01-17T10:39:19.768379Z","iopub.status.idle":"2024-01-17T10:39:19.774231Z","shell.execute_reply.started":"2024-01-17T10:39:19.768352Z","shell.execute_reply":"2024-01-17T10:39:19.772513Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nFind the synonyms of the following word: 'Tenacious'.\n\n### Response:\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **We can merge both paths into one**","metadata":{}},{"cell_type":"code","source":"def create_prompt(row):\n    return prompt_no_input(row) if row[\"input\"] == \"\" else prompt_input(row)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:40:14.851421Z","iopub.execute_input":"2024-01-17T10:40:14.851980Z","iopub.status.idle":"2024-01-17T10:40:14.858163Z","shell.execute_reply.started":"2024-01-17T10:40:14.851947Z","shell.execute_reply":"2024-01-17T10:40:14.856346Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"prompts = [create_prompt(row) for row in alpaca]","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:40:30.371060Z","iopub.execute_input":"2024-01-17T10:40:30.371421Z","iopub.status.idle":"2024-01-17T10:40:30.440547Z","shell.execute_reply.started":"2024-01-17T10:40:30.371392Z","shell.execute_reply":"2024-01-17T10:40:30.439550Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### **End-of-String tokens (EOS)**\nThis token is essential because it tells the model when to stop producing text \\\nFor LLaMa models, it is `EOS_TOKEN = \"</s>\"`","metadata":{}},{"cell_type":"code","source":"# Append EOS after each response\nEOS_TOKEN = \"</s>\"\noutputs = [row[\"output\"] + EOS_TOKEN for row in alpaca]","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:06:45.184949Z","iopub.execute_input":"2024-01-17T11:06:45.185328Z","iopub.status.idle":"2024-01-17T11:06:45.225684Z","shell.execute_reply.started":"2024-01-17T11:06:45.185300Z","shell.execute_reply":"2024-01-17T11:06:45.224739Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(outputs[0])","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:06:54.206273Z","iopub.execute_input":"2024-01-17T11:06:54.206754Z","iopub.status.idle":"2024-01-17T11:06:54.213798Z","shell.execute_reply.started":"2024-01-17T11:06:54.206722Z","shell.execute_reply":"2024-01-17T11:06:54.211732Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.</s>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Concatenate instructions and outputs to form dataset**","metadata":{}},{"cell_type":"code","source":"dataset = [{\n    \"prompt\": s,\n    \"output\": t,\n    \"example\": s + t\n} for s, t in zip(prompts, outputs)]","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:08:06.794043Z","iopub.execute_input":"2024-01-17T11:08:06.794392Z","iopub.status.idle":"2024-01-17T11:08:06.990685Z","shell.execute_reply.started":"2024-01-17T11:08:06.794366Z","shell.execute_reply":"2024-01-17T11:08:06.989808Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### **Time to tokenize**\nWe need to convert the dataset into tokens.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:12:17.597487Z","iopub.execute_input":"2024-01-17T11:12:17.597862Z","iopub.status.idle":"2024-01-17T11:12:23.502090Z","shell.execute_reply.started":"2024-01-17T11:12:17.597837Z","shell.execute_reply":"2024-01-17T11:12:23.500471Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model_id = \"mistralai/Mistral-7B-v0.1\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:13:16.775256Z","iopub.execute_input":"2024-01-17T11:13:16.775683Z","iopub.status.idle":"2024-01-17T11:13:17.500046Z","shell.execute_reply.started":"2024-01-17T11:13:16.775650Z","shell.execute_reply":"2024-01-17T11:13:17.497834Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98b66304fe754d928430c8fbb1ff5756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b7a761d63724066af2df3f50183598d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1883bcc1780400088b42f018e8d8695"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5115fc1fafd141308b77b0c98f068b21"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Sample tokens**","metadata":{}},{"cell_type":"code","source":"tokenizer.encode(\n    \"This sentence is sentenced for tokenization!\",\n    padding = \"max_length\",\n    max_length = 10,\n    return_tensors = \"pt\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:17:12.506077Z","iopub.execute_input":"2024-01-17T11:17:12.506447Z","iopub.status.idle":"2024-01-17T11:17:12.568945Z","shell.execute_reply.started":"2024-01-17T11:17:12.506417Z","shell.execute_reply":"2024-01-17T11:17:12.567949Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"tensor([[    1,   851, 12271,   349,  2662,  4697,   354,  6029,  1837, 28808]])"},"metadata":{}}]},{"cell_type":"markdown","source":"### **Creating a train-eval split**","metadata":{}},{"cell_type":"code","source":"import random\n\n# shuffle in-place\nrandom.shuffle(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:17:45.929710Z","iopub.execute_input":"2024-01-17T11:17:45.930545Z","iopub.status.idle":"2024-01-17T11:17:45.973761Z","shell.execute_reply.started":"2024-01-17T11:17:45.930511Z","shell.execute_reply":"2024-01-17T11:17:45.972003Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train_dataset = dataset[:-1000]\neval_dataset = dataset[-1000:]\n\ntrain_table = pd.DataFrame(train_dataset)\neval_table = pd.DataFrame(eval_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:25:35.317602Z","iopub.execute_input":"2024-01-17T11:25:35.318391Z","iopub.status.idle":"2024-01-17T11:25:35.435727Z","shell.execute_reply.started":"2024-01-17T11:25:35.318359Z","shell.execute_reply":"2024-01-17T11:25:35.434177Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### **Packing: Combine multiple samples into a longer sequence**\n> To make training more efficient and use the longer context of these LLMs we'll do something called **\"packing\"** \\\nWe will combine multiple examples to fill the model's memory and make training more efficient instead of feeding examples individually.\n\nThe main idea here is that the instruction/output samples are short, so let's concatenate a bunch of them together, separated by the EOS token.","metadata":{}},{"cell_type":"code","source":"max_seq_len = 1024","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:29:51.395333Z","iopub.execute_input":"2024-01-17T11:29:51.395741Z","iopub.status.idle":"2024-01-17T11:29:51.400937Z","shell.execute_reply.started":"2024-01-17T11:29:51.395709Z","shell.execute_reply":"2024-01-17T11:29:51.399683Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def pack(dataset, max_seq_len = 1024):\n    tkds_ids = tokenizer([s[\"example\"] for s in dataset])[\"input_ids\"]\n    all_token_ids = []\n    packed_ds = []\n    \n    for tokenized_input in tkds_ids:\n        all_token_ids.extend(tokenized_input + [tokenizer.eos_token_id])\n\n    for i in range(0, len(all_token_ids), max_seq_len+1):\n        input_ids = all_token_ids[i : i + max_seq_len+1]\n        \n        if len(input_ids) == (max_seq_len+1):\n            packed_ds.append({ \"input_ids\": input_ids[:-1], \"labels\": input_ids[1:] })\n\n    return packed_ds","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:30:36.650090Z","iopub.execute_input":"2024-01-17T11:30:36.650488Z","iopub.status.idle":"2024-01-17T11:30:36.663809Z","shell.execute_reply.started":"2024-01-17T11:30:36.650447Z","shell.execute_reply":"2024-01-17T11:30:36.661675Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train_ds_packed = pack(train_dataset)\neval_ds_packed = pack(eval_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:30:42.666583Z","iopub.execute_input":"2024-01-17T11:30:42.667051Z","iopub.status.idle":"2024-01-17T11:30:56.211524Z","shell.execute_reply.started":"2024-01-17T11:30:42.667018Z","shell.execute_reply":"2024-01-17T11:30:56.210391Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## **Storing our preprocessed datasets**","metadata":{}},{"cell_type":"code","source":"def save_jsonl(data, filename):\n    with open(filename, \"w\") as file:\n        for entry in data:\n            json.dump(entry, file)\n            file.write(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:33:08.132518Z","iopub.execute_input":"2024-01-17T11:33:08.132969Z","iopub.status.idle":"2024-01-17T11:33:08.139875Z","shell.execute_reply.started":"2024-01-17T11:33:08.132936Z","shell.execute_reply":"2024-01-17T11:33:08.138453Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"save_jsonl(train_ds_packed, \"train_packed_alpaca.jsonl\")\nsave_jsonl(eval_ds_packed, \"eval_packed_alpaca.jsonl\")","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:33:14.359968Z","iopub.execute_input":"2024-01-17T11:33:14.360373Z","iopub.status.idle":"2024-01-17T11:33:29.256817Z","shell.execute_reply.started":"2024-01-17T11:33:14.360339Z","shell.execute_reply":"2024-01-17T11:33:29.254838Z"},"trusted":true},"execution_count":37,"outputs":[]}]}